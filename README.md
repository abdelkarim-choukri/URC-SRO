# URC-SRO Research Prototype

This repository hosts the codebase for implementing **Unified Retrieval Controller (URC)** and **Self-Regulation Orchestrator (SRO)** modules in a modern RAG pipeline.
The goal is a controllable, auditable system that retrieves *just enough* evidence and validates reasoning before answering.

---

## ğŸ“Œ Project Goal

* Improve retrieval timing & relevance
* Enhance reasoning quality via self-critique
* Reduce compute costs while maintaining accuracy

---

## ğŸ›  Tech Stack

| **Component**       | **Stack**                                                   |
| ------------------- | ----------------------------------------------------------- |
| **Language Models** | DeepSeek-R1 (or any HF model) via Hugging Face Transformers |
| **Retrieval**       | FAISS vector search (LlamaIndex optional)                   |
| **Adapters**        | LoRA (PEFT) for lightweight fine-tuning                     |
| **RL Training**     | PPO/DPO via TRL library                                     |

---

## ğŸ“‚ Folder Structure

```
URC-SRO/
â”œâ”€â”€ urc_sro/                      # Main Python package
â”‚   â”œâ”€â”€ types.py                  # Data models (Document, Metadata, etc.)
â”‚   â”œâ”€â”€ config.py                 # Pydantic settings
â”‚   â”œâ”€â”€ pipeline.py               # High-level coordinator (URC â†’ SRO â†’ answer)
â”‚   â”œâ”€â”€ factory.py                # Helpers to assemble mock or GPU pipelines
â”‚   â”œâ”€â”€ llm_interfaces.py         # Protocol for LLM adapters
â”‚   â”œâ”€â”€ urc/                      # Unified Retrieval Controller
â”‚   â”‚   â”œâ”€â”€ complexity.py         # QueryComplexityEstimator
â”‚   â”‚   â”œâ”€â”€ router.py             # SourceRouter
â”‚   â”‚   â”œâ”€â”€ policy.py             # Cost-Aware Retrieval Policy
â”‚   â”‚   â”œâ”€â”€ retriever.py          # BaseRetriever + UnifiedRetrievalController
â”‚   â”‚   â”œâ”€â”€ in_memory.py          # InMemoryRetriever (mock)
â”‚   â”‚   â”œâ”€â”€ embeddings.py         # Sentence-Transformers wrapper
â”‚   â”‚   â”œâ”€â”€ faiss_retriever.py    # FAISSRetriever + save/load helpers
â”‚   â”‚   â”œâ”€â”€ rerank.py             # Re-rankers (stub & cross-encoder)
â”‚   â”‚   â””â”€â”€ allocator.py          # Token-budgeted ContextAllocator
â”‚   â”œâ”€â”€ sro/                      # Self-Regulation Orchestrator
â”‚   â”‚   â”œâ”€â”€ orchestrator.py       # Iterative generate â†’ verify â†’ retry loop
â”‚   â”‚   â”œâ”€â”€ step_verify.py        # Simple verifier stub
â”‚   â”‚   â”œâ”€â”€ nli_step_verifier.py  # NLI-based verifier (e.g., DeBERTa-v3)
â”‚   â”‚   â”œâ”€â”€ evidence_monitor.py   # Heuristic support/contradiction scoring
â”‚   â”‚   â”œâ”€â”€ conflict_resolver.py  # (planned) Resolve conflicting evidence
â”‚   â”‚   â”œâ”€â”€ citation_auditor.py   # (planned) Citation precision/recall
â”‚   â”‚   â”œâ”€â”€ confidence_gate.py    # (planned) Abstain thresholding
â”‚   â”‚   â””â”€â”€ coverage_auditor.py   # (planned) Completeness checks
â”‚   â”œâ”€â”€ adapters/                 # LLM adapters (mock + HF)
â”‚   â”‚   â”œâ”€â”€ hf_llm.py             # HFGenerativeLLM + TrivialLLM
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ io/                       # Corpus loaders
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ loaders.py
â”‚   â””â”€â”€ eval/                     # Evaluation adapters
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ ragas_adapter.py      # RAGAS harness (faithfulness, relevancy)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## âš¡ 30-Second Quickstart

```bash
pip install -r requirements.txt

# Mock-only demo (no heavy models)
python -m urc_sro.examples.mock_entry

# GPU demo with FAISS
python -m urc_sro.examples.ingest_corpus --input_dir ./data --output_dir ./faiss_store
python -m urc_sro.examples.gpu_entry
```

---

## ğŸ§­ The Journey (Plain Words)

| **Step** | **Who** | **What happens**                                                                                                    |
| -------- | ------- | ------------------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£      | **URC** | Estimates query difficulty â†’ selects sources â†’ decides how many docs to fetch.                                      |
| 2ï¸âƒ£      | **URC** | Retrieves candidates â†’ (optionally) re-ranks â†’ packs them into a token-budgeted context.                            |
| 3ï¸âƒ£      | **SRO** | Drafts an answer (plus brief reasoning steps) grounded in the retrieved context.                                    |
| 4ï¸âƒ£      | **SRO** | Verifies a key step via NLI; if support is weak, loops back to **URC** to fetch more evidence (bounded iterations). |
| 5ï¸âƒ£      | **SRO** | Returns a grounded answerâ€”or politely abstains if evidence remains insufficient.                                    |

---

## âœ… What Works Today

* **Retrievers:** In-memory (keyword) and FAISS (vector)
* **Re-Ranker:** Optional cross-encoder
* **LLMs:** TrivialLLM (mock) and a Hugging Face wrapper (real)
* **Verification:** NLI-based step verifier
* **Evaluation:** RAGAS harness (faithfulness & relevancy)

---

## ğŸ”® Next Steps

| **Phase**       | **Deliverable**                                 |
| --------------- | ----------------------------------------------- |
| Learned Routing | Replace heuristics with trained policies        |
| Audits          | Conflict resolution & citation precision/recall |
| Fine-Tuning     | LoRA adapters + PPO/DPO via TRL                 |

---

## ğŸ“š References

* [DeepSeek-R1](https://huggingface.co/deepseek-ai)
* [Hugging Face Transformers](https://huggingface.co/docs/transformers)
* [FAISS](https://github.com/facebookresearch/faiss)
* [LlamaIndex](https://docs.llamaindex.ai/)
* [PEFT LoRA](https://huggingface.co/docs/peft)
* [TRL PPO/DPO](https://huggingface.co/docs/trl)
